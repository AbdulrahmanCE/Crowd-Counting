{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Crowd Counting\\Crowd Counting - Model\\Model.py:90: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  dm = h5py.File(ph, 'r')['density'].value.astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size: 452 452 452\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "# from utils_gen import gen_paths_img_dm, gen_var_from_paths\n",
    "# from utils_imgproc import norm_by_imagenet\n",
    "from Model import CreateModel\n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "\n",
    "train = CreateModel()\n",
    "# Settings\n",
    "net = 'CSRNet'\n",
    "dataset = 'mixed_data'\n",
    "\n",
    "# # Generate paths of (train, test) x (img, dm)\n",
    "# train_img_paths = []\n",
    "# train_dm_paths = []\n",
    "test_img_paths = []\n",
    "test_dm_paths = []\n",
    "\n",
    "train_paths = 'Data/NewData/train/images'\n",
    "test_paths = 'Data/NewData/test/images'\n",
    "\n",
    "# train_B_paths = 'Data/NewData/part_A/train/images'\n",
    "# test_B_paths = 'Data/NewData/part_A/test/images'\n",
    "\n",
    "# for path in glob.glob(os.path.join(train_paths, '*.jpg')):\n",
    "#     train_img_paths.append(path)\n",
    "#     train_dm_paths.append(path.replace('.jpg', '.h5').replace('images', 'density-maps'))\n",
    "\n",
    "for path in glob.glob(os.path.join(test_paths, '*.jpg')):\n",
    "    test_img_paths.append(path)\n",
    "    test_dm_paths.append(path.replace('.jpg', '.h5').replace('images', 'density-maps'))\n",
    "\n",
    "# train_x = train.gen_var_from_paths(train_img_paths[:], unit_len=None)\n",
    "# train_y = train.gen_var_from_paths(train_dm_paths[:], stride=8, unit_len=None)\n",
    "# print('Train data size:', train_x.shape[0], train_y.shape[0], len(train_img_paths))\n",
    "\n",
    "test_x = train.gen_var_from_paths(test_img_paths[:], unit_len=None)\n",
    "test_y = train.gen_var_from_paths(test_dm_paths[:], stride=8, unit_len=None)\n",
    "test_x = train.norm_by_imagenet(test_x)\n",
    "print('Test data size:', test_x.shape[0], test_y.shape[0], len(test_img_paths))\n",
    "\n",
    "\n",
    "\n",
    "# weights_dir = 'weights_' + dataset + \"{}\".format(datetime.datetime.now())\n",
    "# if not os.path.exists(weights_dir):\n",
    "#     os.makedirs(weights_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, None, None, 256)   1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, None, None, 128)   295040    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, None, None, 64)    73792     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, None, None, 1)     65        \n",
      "=================================================================\n",
      "Total params: 16,263,489\n",
      "Trainable params: 8,628,225\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "# from CSRNet import CSRNet\n",
    "\n",
    "# # Create empty directory for saving weights during training\n",
    "# if os.path.exists(weights_dir):\n",
    "#     shutil.rmtree(weights_dir)\n",
    "# os.makedirs(weights_dir)\n",
    "\n",
    "# Settings of network\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "LOSS = 'MSE'\n",
    "optimizer = Adam(lr=1e-5)\n",
    "\n",
    "# Create my model\n",
    "model = train.CSRNet(input_shape=(None, None, 3))\n",
    "model.compile(optimizer=optimizer, loss='MSE')\n",
    "model.summary()\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "plot_model(model, 'models/{}.png'.format(net))\n",
    "with open('./models/{}.json'.format(net), 'w') as fout:\n",
    "    fout.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from time import time, ctime\n",
    "# from utils_imgproc import image_preprocessing\n",
    "# from utils_callback import eval_loss, callbacks_during_train\n",
    "\n",
    "\n",
    "# Settings of training\n",
    "batch_size = 1\n",
    "epoch = 250\n",
    "val_rate = 0.5\n",
    "val_rate_dec = {'A': [80, 70], 'mixed_data': [9, 8.5]}\n",
    "# len_train = train_x.shape[0]\n",
    "# num_iter = int((len_train-0.1) // batch_size + 1)\n",
    "best_values = {'mae': 1e5, 'rmse': 1e5, 'sfn': 1e5, 'mape': 1e5}\n",
    "losses = [[1e5, 1e5, 1e5, 1e5]]\n",
    "# Settings of display\n",
    "dis_idx = 16 if dataset == 'mixed_data' else 0\n",
    "dis_path = test_img_paths[dis_idx]\n",
    "dis_x = test_x[dis_idx]\n",
    "dis_y = test_y[dis_idx]\n",
    "dis_lim = (5, 35) if dataset == 'mixed_data' else (40, 150)\n",
    "time_st = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training iterations\n",
    "for ep in range(epoch):\n",
    "    for idx_train in range(0, len_train, batch_size):\n",
    "        dis_epoch = str(ep+1)+'-'+str(idx_train+1)+'_'+str(len_train)\n",
    "        x, y = train_x[idx_train:idx_train+batch_size], train_y[idx_train:idx_train+batch_size]\n",
    "        # Preprocessings on raw images\n",
    "        x, y = train.image_preprocessing(\n",
    "            x, y,\n",
    "            flip_hor=True\n",
    "        )\n",
    "        model.fit(x, y, batch_size=1, verbose=0)\n",
    "        idx_val = (idx_train / batch_size + 1)\n",
    "        # Eval losses and save models\n",
    "        if idx_val % (num_iter * val_rate) == 0:\n",
    "            # To see predictions during training in directory 'tmp'\n",
    "#             callbacks_during_train(\n",
    "#                 model, dis_x=dis_x, dis_y=dis_y, dis_path=dis_path,\n",
    "#                 net=net, epoch=dis_epoch\n",
    "#             )\n",
    "            loss = train.eval_loss(model, test_x, test_y, quality=False)\n",
    "            if loss[0] < val_rate_dec[dataset][0]:\n",
    "                val_rate = min(val_rate, 0.25)\n",
    "            if loss[0] < val_rate_dec[dataset][1]:\n",
    "                val_rate = min(val_rate, 0.1)\n",
    "            losses.append(loss)\n",
    "            if (loss[0] < best_values['mae']) or (loss[0] == best_values['mae'] and loss[1] < best_values['rmse']):\n",
    "                model.save_weights(os.path.join(weights_dir, '{}_best.hdf5'.format(net)))\n",
    "            for idx_best in range(len(loss)):\n",
    "                if loss[idx_best] < best_values[list(best_values.keys())[idx_best]]:\n",
    "                    best_values[list(best_values.keys())[idx_best]] = loss[idx_best]\n",
    "                    to_save = True\n",
    "            if to_save:\n",
    "                path_save = os.path.join(weights_dir, ''.join([\n",
    "                    net,\n",
    "                    '_MAE', str(round(loss[0], 3)), '_RMSE', str(round(loss[1], 3)),\n",
    "                    '_SFN', str(round(loss[2], 3)), '_MAPE', str(round(loss[3], 3)),\n",
    "                    '_epoch', str(ep+1), '-', str(idx_val), '.hdf5'\n",
    "                ]))\n",
    "                model.save_weights(path_save)\n",
    "                to_save = False\n",
    "        # Progress panel\n",
    "        time_consuming = time() - time_st\n",
    "        sys.stdout.write('In epoch {}, with MAE-RMSE-SFN-MAPE={}, time consuming={}m-{}s\\r'.format(\n",
    "            dis_epoch, np.round(np.array(losses)[-1, :], 2),\n",
    "            int(time_consuming/60), int(time_consuming-int(time_consuming/60)*60)\n",
    "        ))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "# Save records\n",
    "losses = np.array(losses[1:])\n",
    "pd.DataFrame(losses).to_csv('{}/loss.csv'.format(weights_dir), index=False, header=['MAE', 'RMSE', 'SFN', 'MAPE'])\n",
    "losses_MAE, losses_RMSE, losses_SFN, losses_MAPE = losses[:, 0], losses[:, 1], losses[:, 2], losses[:, 3]\n",
    "plt.plot(losses_MAE, 'r')\n",
    "plt.plot(losses_RMSE, 'b')\n",
    "multiplier = int(round(dis_lim[0] / (np.min(losses_SFN)+0.1)))\n",
    "plt.plot(losses_SFN * multiplier, 'g')\n",
    "plt.legend(['MAE', 'RMSE', 'SFN*{}'.format(multiplier)])\n",
    "plt.ylim(dis_lim)\n",
    "plt.title('Val_losses in {} epochs'.format(epoch))\n",
    "plt.savefig('{}/{}_val_loss.png'.format(weights_dir, net))\n",
    "plt.show()\n",
    "\n",
    "# Rename weights_dir by the trainging end time, to prevent the careless deletion or overwriting\n",
    "end_time_of_train = '-'.join(ctime().split()[:-2])\n",
    "suffix_new_dir = '_{}_{}_bestMAE{}_{}'.format(dataset, LOSS, str(round(best_values['mae'], 3)), end_time_of_train)\n",
    "weights_dir_neo = 'weights'+suffix_new_dir\n",
    "shutil.move('weights_{}'.format(dataset), weights_dir_neo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (3, 3, 512, 512) and (512, 512, 5, 5) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-336ac6e47d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweights_dir_neo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weights_mixed_data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/{}.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights_mixed_data_EXP_1/CSRNet_best.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mct_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mct_gts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2209\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2210\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2211\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2213\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    706\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[0;32m    707\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m   \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3574\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3575\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3576\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3577\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3578\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\.conda\\envs\\crowd_counting\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \"\"\"\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (3, 3, 512, 512) and (512, 512, 5, 5) are incompatible"
     ]
    }
   ],
   "source": [
    "# Analysis on results\n",
    "dis_idx = 16 if dataset == 'mixed_data' else 0\n",
    "weights_dir_neo = 'weights_mixed_data'\n",
    "model = model_from_json(open('models/{}.json'.format(net), 'r').read())\n",
    "model.load_weights('weights_mixed_data_EXP_1/CSRNet_best.hdf5')\n",
    "ct_preds = []\n",
    "ct_gts = []\n",
    "for i in range(len(test_x[:])):\n",
    "    if i % 100 == 0:\n",
    "        print('{}/{}'.format(i, len(test_x)))\n",
    "    i += 0\n",
    "    test_x_display = np.squeeze(test_x[i])\n",
    "    test_y_display = np.squeeze(test_y[i])\n",
    "    path_test_display = test_img_paths[i]\n",
    "    pred = np.squeeze(model.predict(np.expand_dims(test_x_display, axis=0)))\n",
    "    ct_pred = np.sum(pred)\n",
    "    ct_gt = round(np.sum(test_y_display))\n",
    "    ct_preds.append(ct_pred)\n",
    "    ct_gts.append(ct_gt)\n",
    "plt.plot(ct_preds, 'r>')\n",
    "plt.plot(ct_gts, 'b+')\n",
    "plt.legend(['ct_preds', 'ct_gts'])\n",
    "plt.title('Pred vs GT')\n",
    "plt.show()\n",
    "error = np.array(ct_preds) - np.array(ct_gts)\n",
    "plt.plot(error)\n",
    "plt.title('Pred - GT, mean = {}, MAE={}'.format(\n",
    "    str(round(np.mean(error), 3)),\n",
    "    str(round(np.mean(np.abs(error)), 3))\n",
    "))\n",
    "plt.show()\n",
    "idx_max_error = np.argsort(np.abs(error))[::-1]\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the 5 worst samples\n",
    "for worst_idx in idx_max_error[:30].tolist() + [dis_idx]:\n",
    "    test_x_display = np.squeeze(test_x[worst_idx])\n",
    "    test_y_display = np.squeeze(test_y[worst_idx])\n",
    "    path_test_display = test_img_paths[worst_idx]\n",
    "    pred = np.squeeze(model.predict(np.expand_dims(test_x_display, axis=0)))\n",
    "    fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "    ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_test_display), cv2.COLOR_BGR2RGB))\n",
    "    ax_x_ori.set_title('Original Image')\n",
    "    ax_y.imshow(test_y_display, cmap=plt.cm.jet)\n",
    "    ax_y.set_title('Ground_truth: ' + str(np.sum(test_y_display)))\n",
    "    ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "    ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(100, 300, 16):\n",
    "    test_x_display = np.squeeze(test_x[idx])\n",
    "    test_y_display = np.squeeze(test_y[idx])\n",
    "    path_test_display = test_img_paths[idx]\n",
    "    pred = np.squeeze(model.predict(np.expand_dims(test_x_display, axis=0)))\n",
    "    fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "    ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_test_display), cv2.COLOR_BGR2RGB))\n",
    "    ax_x_ori.set_title('Original Image')\n",
    "    ax_y.imshow(test_y_display, cmap=plt.cm.jet)\n",
    "    ax_y.set_title('Ground_truth: ' + str(np.sum(test_y_display)))\n",
    "    ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "    ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Crowd Counting\\Crowd Counting - Model\\Model.py:187: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  losses_MAPE.append(np.abs(np.sum(preds[idx_pd]) - GT[idx_pd]) / GT[idx_pd])\n",
      "D:\\Crowd Counting\\Crowd Counting - Model\\Model.py:199: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n",
      "  psnr_ = compare_psnr(preds[idx_pd], DM[idx_pd], data_range=data_range)\n",
      "D:\\Crowd Counting\\Crowd Counting - Model\\Model.py:200: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  ssim_ = compare_ssim(preds[idx_pd], DM[idx_pd], data_range=data_range)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.17998 259.2897 14.861884 inf 20.93780997580482 0.5498323361115727\n"
     ]
    }
   ],
   "source": [
    "# Generate losses and the image quality\n",
    "# model = model_from_json(open('models/{}.json'.format(net), 'r').read())\n",
    "# model.load_weights('{}/{}_best.hdf5'.format('weights_', net))\n",
    "# from utils_callback import eval_loss\n",
    "lossMAE, lossRMSE, lossSFN, lossMAPE, PSNR, SSIM = train.eval_loss(\n",
    "    model, test_x, test_y, quality=True\n",
    ")\n",
    "print(lossMAE, lossRMSE, lossSFN, lossMAPE, PSNR, SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Crowd Counting - Model)",
   "language": "python",
   "name": "pycharm-656e5223"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
